{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa8f844a-2f60-43b8-83a4-867801f01dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fine-tune SAM on Liebherr Dataset\n",
    "# https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/SAM/Fine_tune_SAM_(segment_anything)_on_a_custom_dataset.ipynb#scrollTo=XC35CzLxfdQU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79e28afd-6f8d-4a0c-8ff2-d8cf236775a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 08:41:31.804423: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-25 08:41:31.852070: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 08:41:32.992702: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import monai\n",
    "import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torchvision.transforms import ToTensor, Compose\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn.functional import threshold, normalize\n",
    "from torchmetrics.classification import BinaryJaccardIndex\n",
    "\n",
    "from segment_anything.utils.transforms import ResizeLongestSide\n",
    "\n",
    "from datasets import Embedding_Dataset\n",
    "from utils import SAMPreprocess, PILToNumpy, NumpyToTensor, SamplePoint, embedding_collate, is_valid_file\n",
    "from models import SAM_Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37849bae-e788-4b53-9d9d-3f70ebdc49fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_output = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6302f5ef-2204-4d42-aebd-9596b499ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SAM_Baseline(multi_output)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "# make sure we only compute gradients for mask decoder\n",
    "for name, param in model.sam_model.named_parameters():\n",
    "    if name.startswith(\"vision_encoder\") or name.startswith(\"prompt_encoder\"):\n",
    "        param.requires_grad_(False)\n",
    "\n",
    "jaccard = BinaryJaccardIndex().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43cf0154-d392-4d8c-97bf-bf25e6e5a8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_transform = ResizeLongestSide(model.img_size)\n",
    "target_transform = Compose([\n",
    "    sam_transform.apply_image_torch, # rescale\n",
    "    SAMPreprocess(model.img_size, normalize=False), # padding\n",
    "    SamplePoint(),\n",
    "])\n",
    "transform = Compose([\n",
    "    PILToNumpy(),\n",
    "    sam_transform.apply_image, # rescale\n",
    "    NumpyToTensor(),\n",
    "    SAMPreprocess(model.img_size) # padding\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5f88aa9-ac90-41f6-8160-496adbc54b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 8\n",
    "lr = 1e-5\n",
    "\n",
    "folder_path = '/pfs/work7/workspace/scratch/ul_xto11-FSSAM/Liebherr/dataset'\n",
    "dataset = Embedding_Dataset(root=folder_path, transform=transform, target_transform=target_transform, is_valid_file=is_valid_file)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.7 * dataset_size)\n",
    "val_size = int(0.15 * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size], generator)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, collate_fn=embedding_collate)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, collate_fn=embedding_collate)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, collate_fn=embedding_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baba0429-fe3b-42f0-aa49-46cdc23b0518",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.sam_model.mask_decoder.parameters(), lr=lr, weight_decay=0)\n",
    "criterion = monai.losses.DiceFocalLoss(sigmoid=True, squared_pred=True, lambda_focal=20.) # maybe include_background=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89dd5428-2f29-4744-92f7-f348b4d0db26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oracle(target, prediction):\n",
    "    B, N, H, W = prediction.shape\n",
    "    target_flat = target.repeat(1, N, 1, 1).reshape(B * N, H, W)\n",
    "    prediction_flat = prediction.reshape(B * N, H, W)\n",
    "    iou = []\n",
    "    for t, p in zip(target_flat, prediction_flat):\n",
    "        iou.append(jaccard(t, p))\n",
    "    iou = torch.tensor(iou).reshape(B, N).to(device)\n",
    "    max_i = torch.argmax(iou, 1)\n",
    "    return iou, max_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "200595b3-3f11-40a6-87bf-d0dccc304d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, epoch, criterion, optimizer, dataloader, device):\n",
    "    model.train()\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_iou = 0.0\n",
    "\n",
    "    for batch, (images, masks, points, embeddings) in enumerate(tqdm.tqdm(dataloader)):\n",
    "        # Transfer Data to GPU if available\n",
    "        embeddings, points, masks = embeddings.to(device), points.to(device), masks.to(device)\n",
    "\n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward Pass\n",
    "        if multi_output:\n",
    "            outputs, iou_pred = model(embeddings, points)\n",
    "            iou, oracle_i = get_oracle(masks > 0, outputs > 0)\n",
    "            oracle_outputs = outputs[range(len(outputs)), oracle_i].unsqueeze(1)\n",
    "            outputs = outputs[range(len(outputs)), torch.argmax(iou_pred, dim=1)].unsqueeze(1)\n",
    "            loss = criterion(oracle_outputs, masks) + 0.1 * torch.nn.functional.mse_loss(iou_pred, iou) # Compute Loss\n",
    "        else:\n",
    "            outputs = model(embeddings, points)\n",
    "            loss = criterion(outputs, masks) # Compute Loss\n",
    "\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate Loss\n",
    "        running_loss += loss.item() * embeddings.size(0)\n",
    "        running_iou += jaccard(masks > 0, outputs > 0) * embeddings.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / num_samples\n",
    "    epoch_iou = running_iou / num_samples\n",
    "\n",
    "    return epoch_loss, epoch_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cec44f86-7dab-43f9-ae0a-0a937c2d2ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, epoch, criterion, optimizer, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        running_iou = 0.0\n",
    "\n",
    "        for batch, (images, masks, points, embeddings) in enumerate(tqdm.tqdm(dataloader)):\n",
    "            # Transfer Data to GPU if available\n",
    "            embeddings, points, masks = embeddings.to(device), points.to(device), masks.to(device)\n",
    "\n",
    "            # Clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward Pass\n",
    "            if multi_output:\n",
    "                outputs, iou_pred = model(embeddings, points)\n",
    "                iou, oracle_i = get_oracle(masks > 0, outputs > 0)\n",
    "                oracle_outputs = outputs[range(len(outputs)), oracle_i].unsqueeze(1)\n",
    "                outputs = outputs[range(len(outputs)), torch.argmax(iou_pred, dim=1)].unsqueeze(1)\n",
    "                loss = criterion(oracle_outputs, masks) + 0.1 * torch.nn.functional.mse_loss(iou_pred, iou) # Compute Loss\n",
    "            else:\n",
    "                outputs = model(embeddings, points)\n",
    "                loss = criterion(outputs, masks) # Compute Loss\n",
    "\n",
    "            # Calculate Loss\n",
    "            running_loss += loss.item() * embeddings.size(0)\n",
    "            running_iou += jaccard(masks > 0, outputs > 0) * embeddings.size(0)\n",
    "            \n",
    "        epoch_loss = running_loss / num_samples\n",
    "        epoch_iou = running_iou / num_samples\n",
    "\n",
    "    return epoch_loss, epoch_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6e101c4-e131-4cf8-9fc2-2788f22ef06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrankfundel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/pfs/data5/home/ul/ul_student/ul_xto11/FewShotSAM/wandb/run-20230925_084251-j1n43kyz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/frankfundel/Fine-Tune-SAM/runs/j1n43kyz' target=\"_blank\">absurd-pine-27</a></strong> to <a href='https://wandb.ai/frankfundel/Fine-Tune-SAM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/frankfundel/Fine-Tune-SAM' target=\"_blank\">https://wandb.ai/frankfundel/Fine-Tune-SAM</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/frankfundel/Fine-Tune-SAM/runs/j1n43kyz' target=\"_blank\">https://wandb.ai/frankfundel/Fine-Tune-SAM/runs/j1n43kyz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/frankfundel/Fine-Tune-SAM/runs/j1n43kyz?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x14f403a988b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb_config = {\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": lr,\n",
    "    \"batch_size\": batch_size,\n",
    "}\n",
    "\n",
    "wandb.init(project=\"Fine-Tune-SAM\", entity=\"frankfundel\", config=wandb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1701637-7529-4a2a-8bca-f73f79c3c396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 0 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [04:10<00:00,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3147 IoU: 0.5457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:52<00:00,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3120 IoU: 0.5885\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 1 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [02:47<00:00,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2058 IoU: 0.6280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:36<00:00,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2212 IoU: 0.5917\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [02:45<00:00,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1817 IoU: 0.6326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:35<00:00,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2047 IoU: 0.6010\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 3 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [02:47<00:00,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1749 IoU: 0.6267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:35<00:00,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2014 IoU: 0.6541\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 4 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [02:45<00:00,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1706 IoU: 0.6467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:36<00:00,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.1998 IoU: 0.6191\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 5 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [02:47<00:00,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1653 IoU: 0.6480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:37<00:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.1824 IoU: 0.6637\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 6 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [02:48<00:00,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1665 IoU: 0.6626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:37<00:00,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.1730 IoU: 0.6405\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 7 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [02:56<00:00,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1690 IoU: 0.6484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:38<00:00,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.1636 IoU: 0.6641\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 8 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [02:52<00:00,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1521 IoU: 0.6831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:36<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.1727 IoU: 0.6271\n",
      "==================== Starting at epoch 9 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 75/75 [02:48<00:00,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1469 IoU: 0.6844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:35<00:00,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.1425 IoU: 0.6868\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "min_val_loss = np.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    end = time.time()\n",
    "    print(f\"==================== Starting at epoch {epoch} ====================\", flush=True)\n",
    "    \n",
    "    train_loss, train_iou = train_epoch(model, epoch, criterion, optimizer, train_loader, device)\n",
    "    print('Training loss: {:.4f} IoU: {:.4f}'.format(train_loss, train_iou), flush=True)\n",
    "    \n",
    "    val_loss, val_iou = test_epoch(model, epoch, criterion, optimizer, val_loader, device)\n",
    "    print('Validation loss: {:.4f} IoU: {:.4f}'.format(val_loss, val_iou), flush=True)\n",
    "    \n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_iou\": train_iou,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_iou\": val_iou,\n",
    "    })\n",
    "    \n",
    "    if min_val_loss > val_loss:\n",
    "        print('val_loss decreased, saving model', flush=True)\n",
    "        min_val_loss = val_loss\n",
    "        \n",
    "        # Saving State Dict\n",
    "        torch.save(model.state_dict(), 'Fine-Tune-SAM.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd400c51-89ba-4fb4-9c27-4e95208922a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load after training\n",
    "model.load_state_dict(torch.load('Fine-Tune-SAM.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b464f87-0616-405d-9e66-53cb4359b3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:50<00:00,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1767 IoU: 0.6624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_iou = test_epoch(model, 0, criterion, optimizer, test_loader, device)\n",
    "print('Test loss: {:.4f} IoU: {:.4f}'.format(test_loss, test_iou), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "460ba378-f108-4164-9eed-d56bc188f30a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb9c47c1d984b4098cb66fde242688b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_iou</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_iou</td><td>▁▅▅▅▆▆▇▆██</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▂▂▁▁</td></tr><tr><td>val_iou</td><td>▁▁▂▆▃▆▅▆▄█</td></tr><tr><td>val_loss</td><td>█▄▄▃▃▃▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_iou</td><td>0.66241</td></tr><tr><td>test_loss</td><td>0.17667</td></tr><tr><td>train_iou</td><td>0.68439</td></tr><tr><td>train_loss</td><td>0.14687</td></tr><tr><td>val_iou</td><td>0.68678</td></tr><tr><td>val_loss</td><td>0.1425</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">absurd-pine-27</strong> at: <a href='https://wandb.ai/frankfundel/Fine-Tune-SAM/runs/j1n43kyz' target=\"_blank\">https://wandb.ai/frankfundel/Fine-Tune-SAM/runs/j1n43kyz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230925_084251-j1n43kyz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.log({\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_iou\": test_iou\n",
    "})\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637c78e4-eb91-4d1d-ba0f-71e0c5c3d3d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupytervenv)",
   "language": "python",
   "name": "jupytervenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
