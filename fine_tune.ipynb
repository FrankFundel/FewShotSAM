{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa8f844a-2f60-43b8-83a4-867801f01dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fine-tune SAM on Liebherr Dataset\n",
    "# https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/SAM/Fine_tune_SAM_(segment_anything)_on_a_custom_dataset.ipynb#scrollTo=XC35CzLxfdQU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79e28afd-6f8d-4a0c-8ff2-d8cf236775a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-27 17:42:30.877908: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-27 17:42:31.635927: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-27 17:42:50.473432: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "from segment_anything.utils.transforms import ResizeLongestSide\n",
    "\n",
    "import monai\n",
    "import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torchvision.transforms import ToTensor, Compose\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn.functional import threshold, normalize\n",
    "from torchmetrics.classification import BinaryJaccardIndex\n",
    "\n",
    "from test import is_valid_file\n",
    "from utils import Embedding_Dataset, SAMPreprocess, PILToNumpy, NumpyToTensor, sample_point, SAMPostprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6302f5ef-2204-4d42-aebd-9596b499ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAM_Fine_Tune(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SAM_Fine_Tune, self).__init__()\n",
    "        self.sam_model = sam_model_registry['vit_b'](checkpoint='sam_vit_b_01ec64.pth')\n",
    "        self.img_size = self.sam_model.image_encoder.img_size\n",
    "        self.postprocess_masks = SAMPostprocess(self.img_size)\n",
    "\n",
    "    def forward(self, embeddings, points):\n",
    "        labels = torch.ones(embeddings.shape[0], 1)\n",
    "        labels.to(points.device)\n",
    "        sparse_embeddings, dense_embeddings = self.sam_model.prompt_encoder(\n",
    "          points=(points.unsqueeze(1), labels),\n",
    "          boxes=None,\n",
    "          masks=None\n",
    "        )\n",
    "        masks, iou_predictions = self.sam_model.mask_decoder(\n",
    "          image_embeddings=embeddings,\n",
    "          image_pe=self.sam_model.prompt_encoder.get_dense_pe(),\n",
    "          sparse_prompt_embeddings=sparse_embeddings,\n",
    "          dense_prompt_embeddings=dense_embeddings,\n",
    "          multimask_output=False, # fine-tuning such that the first decoder output is the best\n",
    "        )\n",
    "        masks = self.postprocess_masks(masks)\n",
    "        #masks = normalize(threshold(masks, 0.0, 0)).to(device) # sigmoid is set to true in dice\n",
    "        return masks # B, 1, 256, 256\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SAM_Fine_Tune()\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "# make sure we only compute gradients for mask decoder\n",
    "for name, param in model.sam_model.named_parameters():\n",
    "    if name.startswith(\"vision_encoder\") or name.startswith(\"prompt_encoder\"):\n",
    "        param.requires_grad_(False)\n",
    "\n",
    "jaccard = BinaryJaccardIndex().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43cf0154-d392-4d8c-97bf-bf25e6e5a8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_transform = ResizeLongestSide(model.img_size)\n",
    "target_transform = Compose([\n",
    "    sam_transform.apply_image_torch, # rescale\n",
    "    SAMPreprocess(model.img_size, normalize=False), # padding\n",
    "    sample_point,\n",
    "])\n",
    "transform = Compose([\n",
    "    PILToNumpy(),\n",
    "    sam_transform.apply_image, # rescale\n",
    "    NumpyToTensor(),\n",
    "    SAMPreprocess(model.img_size) # padding\n",
    "])\n",
    "def custom_collate(batch):\n",
    "    images, targets, embeddings = zip(*batch)\n",
    "    masks, points = zip(*targets)\n",
    "    return torch.stack(images), torch.stack(masks), torch.stack(points), torch.stack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f88aa9-ac90-41f6-8160-496adbc54b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 8\n",
    "lr = 1e-5\n",
    "\n",
    "folder_path = '/pfs/work7/workspace/scratch/ul_xto11-FSSAM/Liebherr/dataset'\n",
    "dataset = Embedding_Dataset(root=folder_path, transform=transform, target_transform=target_transform, is_valid_file=is_valid_file)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.7 * dataset_size)\n",
    "val_size = int(0.15 * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size], generator)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, collate_fn=custom_collate)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, collate_fn=custom_collate)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baba0429-fe3b-42f0-aa49-46cdc23b0518",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.sam_model.mask_decoder.parameters(), lr=lr, weight_decay=0)\n",
    "criterion = monai.losses.DiceFocalLoss(sigmoid=True, squared_pred=True, lambda_focal=20.) # maybe include_background=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "200595b3-3f11-40a6-87bf-d0dccc304d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, epoch, criterion, optimizer, dataloader, device):\n",
    "    model.train()\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_iou = 0.0\n",
    "\n",
    "    for batch, (images, masks, points, embeddings) in enumerate(tqdm.tqdm(dataloader)):\n",
    "        # Transfer Data to GPU if available\n",
    "        embeddings, points, masks = embeddings.to(device), points.to(device), masks.to(device)\n",
    "\n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward Pass\n",
    "        outputs = model(embeddings, points)\n",
    "\n",
    "        # Compute Loss\n",
    "        loss = criterion(outputs, masks)\n",
    "\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update Weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate Loss\n",
    "        running_loss += loss.item() * embeddings.size(0)\n",
    "        running_iou += jaccard(masks > 0, outputs > 0) * embeddings.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / num_samples\n",
    "    epoch_iou = running_iou / num_samples\n",
    "\n",
    "    return epoch_loss, epoch_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cec44f86-7dab-43f9-ae0a-0a937c2d2ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, epoch, criterion, optimizer, dataloader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        running_iou = 0.0\n",
    "\n",
    "        for batch, (images, masks, points, embeddings) in enumerate(tqdm.tqdm(dataloader)):\n",
    "            # Transfer Data to GPU if available\n",
    "            embeddings, points, masks = embeddings.to(device), points.to(device), masks.to(device)\n",
    "\n",
    "            # Clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward Pass\n",
    "            outputs = model(embeddings, points)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = criterion(outputs, masks)\n",
    "\n",
    "            # Calculate Loss\n",
    "            running_loss += loss.item() * embeddings.size(0)\n",
    "            running_iou += jaccard(masks > 0, outputs > 0) * embeddings.size(0)\n",
    "            \n",
    "        epoch_loss = running_loss / num_samples\n",
    "        epoch_iou = running_iou / num_samples\n",
    "\n",
    "    return epoch_loss, epoch_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6e101c4-e131-4cf8-9fc2-2788f22ef06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrankfundel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/pfs/data5/home/ul/ul_student/ul_xto11/FewShotSAM/wandb/run-20230827_174334-nkb0do6a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/frankfundel/Fine-Tune-SAM/runs/nkb0do6a' target=\"_blank\">apricot-bee-16</a></strong> to <a href='https://wandb.ai/frankfundel/Fine-Tune-SAM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/frankfundel/Fine-Tune-SAM' target=\"_blank\">https://wandb.ai/frankfundel/Fine-Tune-SAM</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/frankfundel/Fine-Tune-SAM/runs/nkb0do6a' target=\"_blank\">https://wandb.ai/frankfundel/Fine-Tune-SAM/runs/nkb0do6a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/frankfundel/Fine-Tune-SAM/runs/nkb0do6a?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x14f201873910>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb_config = {\n",
    "    \"epochs\": epochs,\n",
    "    \"lr\": lr,\n",
    "    \"batch_size\": batch_size,\n",
    "}\n",
    "\n",
    "wandb.init(project=\"Fine-Tune-SAM\", entity=\"frankfundel\", config=wandb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1701637-7529-4a2a-8bca-f73f79c3c396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 0 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [04:28<00:00,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4849 IoU: 0.5015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:59<00:00,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3536 IoU: 0.5636\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 1 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [04:05<00:00,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3373 IoU: 0.5775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:52<00:00,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3532 IoU: 0.5753\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 2 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [03:55<00:00,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3152 IoU: 0.6143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:52<00:00,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2868 IoU: 0.6375\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 3 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [04:01<00:00,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3207 IoU: 0.6017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:52<00:00,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2775 IoU: 0.6639\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 4 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [03:59<00:00,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2961 IoU: 0.6117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:52<00:00,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2587 IoU: 0.6372\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 5 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [04:01<00:00,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3030 IoU: 0.6017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:52<00:00,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2855 IoU: 0.6254\n",
      "==================== Starting at epoch 6 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 75/75 [03:56<00:00,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2915 IoU: 0.6212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:51<00:00,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2812 IoU: 0.6092\n",
      "==================== Starting at epoch 7 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 75/75 [04:00<00:00,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2903 IoU: 0.6332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:51<00:00,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2357 IoU: 0.6547\n",
      "val_loss decreased, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Starting at epoch 8 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [03:54<00:00,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2706 IoU: 0.6578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:51<00:00,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2600 IoU: 0.6456\n",
      "==================== Starting at epoch 9 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 75/75 [03:59<00:00,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2647 IoU: 0.6560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 16/16 [00:52<00:00,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2824 IoU: 0.6133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "min_val_loss = np.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    end = time.time()\n",
    "    print(f\"==================== Starting at epoch {epoch} ====================\", flush=True)\n",
    "    \n",
    "    train_loss, train_iou = train_epoch(model, epoch, criterion, optimizer, train_loader, device)\n",
    "    print('Training loss: {:.4f} IoU: {:.4f}'.format(train_loss, train_iou), flush=True)\n",
    "    \n",
    "    val_loss, val_iou = test_epoch(model, epoch, criterion, optimizer, val_loader, device)\n",
    "    print('Validation loss: {:.4f} IoU: {:.4f}'.format(val_loss, val_iou), flush=True)\n",
    "    \n",
    "    wandb.log({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_iou\": train_iou,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_iou\": val_iou,\n",
    "    })\n",
    "    \n",
    "    if min_val_loss > val_loss:\n",
    "        print('val_loss decreased, saving model', flush=True)\n",
    "        min_val_loss = val_loss\n",
    "        \n",
    "        # Saving State Dict\n",
    "        torch.save(model.state_dict(), 'Fine-Tune-SAM.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd400c51-89ba-4fb4-9c27-4e95208922a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load after training\n",
    "model.load_state_dict(torch.load('Fine-Tune-SAM.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b464f87-0616-405d-9e66-53cb4359b3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:02<00:00,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2719 IoU: 0.6458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_iou = test_epoch(model, 0, criterion, optimizer, test_loader, device)\n",
    "print('Test loss: {:.4f} IoU: {:.4f}'.format(test_loss, test_iou), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "460ba378-f108-4164-9eed-d56bc188f30a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec0d9ed8b5f430aaee3677974841e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_iou</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_iou</td><td>▁▄▆▅▆▅▆▇██</td></tr><tr><td>train_loss</td><td>█▃▃▃▂▂▂▂▁▁</td></tr><tr><td>val_iou</td><td>▁▂▆█▆▅▄▇▇▄</td></tr><tr><td>val_loss</td><td>██▄▃▂▄▄▁▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_iou</td><td>0.64576</td></tr><tr><td>test_loss</td><td>0.27187</td></tr><tr><td>train_iou</td><td>0.65602</td></tr><tr><td>train_loss</td><td>0.26473</td></tr><tr><td>val_iou</td><td>0.61334</td></tr><tr><td>val_loss</td><td>0.28243</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">apricot-bee-16</strong> at: <a href='https://wandb.ai/frankfundel/Fine-Tune-SAM/runs/nkb0do6a' target=\"_blank\">https://wandb.ai/frankfundel/Fine-Tune-SAM/runs/nkb0do6a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230827_174334-nkb0do6a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.log({\n",
    "    \"test_loss\": test_loss,\n",
    "    \"test_iou\": test_iou\n",
    "})\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637c78e4-eb91-4d1d-ba0f-71e0c5c3d3d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupytervenv)",
   "language": "python",
   "name": "jupytervenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
