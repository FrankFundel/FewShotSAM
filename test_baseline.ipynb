{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad274da1-82b6-4974-bd52-22983ea73ad9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from test import create_dataloaders, test_model, plot_iou_scores\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "from segment_anything.utils.transforms import ResizeLongestSide\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torchvision.transforms import ToTensor, Compose\n",
    "\n",
    "from utils import Embedding_Dataset, SAMPreprocess, PILToNumpy, NumpyToTensor, sample_point, SAMPostprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b0e2256-94f7-4f98-99bf-c4d6ceeb318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = [\n",
    "    '/pfs/work7/workspace/scratch/ul_xto11-FSSAM/Liebherr/dataset',\n",
    "    '/pfs/work7/workspace/scratch/ul_xto11-FSSAM/FSSAM Datasets/EgoHOS/dataset',\n",
    "    '/pfs/work7/workspace/scratch/ul_xto11-FSSAM/FSSAM Datasets/GTEA/dataset',\n",
    "    '/pfs/work7/workspace/scratch/ul_xto11-FSSAM/FSSAM Datasets/LVIS/dataset',\n",
    "    '/pfs/work7/workspace/scratch/ul_xto11-FSSAM/FSSAM Datasets/NDIS Park/dataset',\n",
    "    '/pfs/work7/workspace/scratch/ul_xto11-FSSAM/FSSAM Datasets/TrashCan/dataset',\n",
    "    '/pfs/work7/workspace/scratch/ul_xto11-FSSAM/FSSAM Datasets/ZeroWaste-f/dataset',\n",
    "]\n",
    "only_liebherr = True\n",
    "load_weights = 'Fine-Tune-SAM.pth'\n",
    "only_test = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2715068-f052-4b8a-ae21-c91f86f9bb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's go\n"
     ]
    }
   ],
   "source": [
    "class SAM_Baseline(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SAM_Baseline, self).__init__()\n",
    "        self.sam_model = sam_model_registry['vit_b'](checkpoint='sam_vit_b_01ec64.pth')\n",
    "        self.img_size = self.sam_model.image_encoder.img_size\n",
    "        self.postprocess_masks = SAMPostprocess(self.img_size)\n",
    "\n",
    "    def forward(self, embeddings, points):\n",
    "        labels = torch.ones(embeddings.shape[0], 1)\n",
    "        labels.to(points.device)\n",
    "        sparse_embeddings, dense_embeddings = self.sam_model.prompt_encoder(\n",
    "          points=(points.unsqueeze(1), labels),\n",
    "          boxes=None,\n",
    "          masks=None\n",
    "        )\n",
    "        masks, iou_predictions = self.sam_model.mask_decoder(\n",
    "          image_embeddings=embeddings,\n",
    "          image_pe=self.sam_model.prompt_encoder.get_dense_pe(),\n",
    "          sparse_prompt_embeddings=sparse_embeddings,\n",
    "          dense_prompt_embeddings=dense_embeddings,\n",
    "          multimask_output=True,\n",
    "        )\n",
    "        masks = self.postprocess_masks(masks)\n",
    "        return masks, iou_predictions # (B, 3, 1024, 1024), (B, 3)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SAM_Baseline()\n",
    "if load_weights is not None:\n",
    "    model.load_state_dict(torch.load(load_weights))\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = DataParallel(model)\n",
    "model.to(device)\n",
    "print(\"Let's go\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "250fd898-9523-4679-8dee-6e9c34649563",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_transform = ResizeLongestSide(model.img_size)\n",
    "target_transform = Compose([\n",
    "    sam_transform.apply_image_torch, # rescale\n",
    "    SAMPreprocess(model.img_size, normalize=False), # padding\n",
    "    sample_point,\n",
    "])\n",
    "transform = Compose([\n",
    "    PILToNumpy(),\n",
    "    sam_transform.apply_image, # rescale\n",
    "    NumpyToTensor(),\n",
    "    SAMPreprocess(model.img_size) # padding\n",
    "])\n",
    "def custom_collate(batch):\n",
    "    images, targets, embeddings = zip(*batch)\n",
    "    masks, points = zip(*targets)\n",
    "    return torch.stack(images), torch.stack(masks), torch.stack(points), torch.stack(embeddings)\n",
    "\n",
    "if only_liebherr:\n",
    "    folder_paths = [folder_paths[0]]\n",
    "    \n",
    "dataloaders = create_dataloaders(folder_paths, transform=transform, target_transform=target_transform, collate_fn=custom_collate,\n",
    "                                 batch_size=8, only_test=only_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa1d8597-68ff-4630-9f41-67c0ab4eca43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Liebherr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:02<00:00,  3.93s/it, IoU=0.608, oracle IoU=0.699]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average IoU tensor(0.6082)\n",
      "Average Oracle IoU tensor(0.6988)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "iou_scores, oracle_iou_scores, dataset_names = test_model(model, dataloaders, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85dc459-8c54-4fa5-ae8a-a795c1b0603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_iou_scores(iou_scores[1:], oracle_iou_scores[1:], dataset_names[1:])\n",
    "print(np.mean(iou_scores[1:]), np.mean(oracle_iou_scores[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ab4fc3-b15b-4ef8-8db0-ece8f2f1bf39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupytervenv)",
   "language": "python",
   "name": "jupytervenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
